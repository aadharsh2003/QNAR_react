{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36136fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Sai\n",
      "[nltk_data]     Rajagopal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Sai\n",
      "[nltk_data]     Rajagopal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing complete! Processed data saved to 'processed_books_content.json'.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download necessary NLTK resources for Arabic\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Arabic stop words\n",
    "stop_words = set(stopwords.words('arabic'))\n",
    "\n",
    "# Paths\n",
    "json_folder = \"books_json\"  # Folder containing JSON files\n",
    "output_file = \"processed_books_content.json\"  # Output file in the main QNARAI folder\n",
    "\n",
    "def load_data(file_path):\n",
    "    \"\"\"Load text data from a JSON file.\"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "        text = next(iter(data.values()))  # Assumes one key-value pair per file where value is the text\n",
    "    return text\n",
    "\n",
    "def clean_arabic_text(text):\n",
    "    \"\"\"Clean Arabic text: remove diacritics, tatweel, punctuation, and extra spaces.\"\"\"\n",
    "    text = re.sub(r'[\\u0610-\\u061A\\u064B-\\u065F]', '', text)  # Remove Arabic diacritics\n",
    "    text = re.sub(r'[\\u0640]', '', text)  # Remove tatweel (kashida)\n",
    "    text = re.sub(r'[^\\u0600-\\u06FF\\s]', '', text)  # Keep only Arabic characters and spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Normalize spaces\n",
    "    return text\n",
    "\n",
    "def process_arabic_text(text):\n",
    "    \"\"\"Tokenize Arabic text, remove stopwords, and normalize to lowercase.\"\"\"\n",
    "    words = word_tokenize(text)  # Tokenize text\n",
    "    words = [word for word in words if word not in stop_words]  # Remove Arabic stopwords\n",
    "    return words\n",
    "\n",
    "def preprocess_books(json_folder):\n",
    "    \"\"\"Preprocess all JSON files in the given folder.\"\"\"\n",
    "    all_books_content = {}\n",
    "    \n",
    "    for file_name in os.listdir(json_folder):\n",
    "        if file_name.endswith('.json'):  # Process only JSON files\n",
    "            file_path = os.path.join(json_folder, file_name)\n",
    "            \n",
    "            # Load, clean, and process text\n",
    "            raw_text = load_data(file_path)\n",
    "            cleaned_text = clean_arabic_text(raw_text)\n",
    "            processed_text = process_arabic_text(cleaned_text)\n",
    "            \n",
    "            # Store processed content\n",
    "            book_name = file_name.replace('_content.json', '')  # Extract book name\n",
    "            all_books_content[book_name] = processed_text\n",
    "    \n",
    "    return all_books_content\n",
    "\n",
    "# Preprocess all books and save output\n",
    "books_content = preprocess_books(json_folder)\n",
    "\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(books_content, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"Preprocessing complete! Processed data saved to '{output_file}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7f5687c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.3.12-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting langchain_community\n",
      "  Downloading langchain_community-0.3.12-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting ollama\n",
      "  Using cached ollama-0.4.4-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.9.0.post1-cp39-cp39-win_amd64.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\sai rajagopal\\anaconda3\\lib\\site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\sai rajagopal\\anaconda3\\lib\\site-packages (from langchain) (1.4.22)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\sai rajagopal\\anaconda3\\lib\\site-packages (from langchain) (3.8.5)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\users\\sai rajagopal\\anaconda3\\lib\\site-packages (from langchain) (4.0.3)\n",
      "Collecting langchain-core<0.4.0,>=0.3.25 (from langchain)\n",
      "  Using cached langchain_core-0.3.25-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.3 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.3-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langsmith<0.3,>=0.1.17 (from langchain)\n",
      "  Using cached langsmith-0.2.3-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in c:\\users\\sai rajagopal\\anaconda3\\lib\\site-packages (from langchain) (1.22.4)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain)\n",
      "  Using cached pydantic-2.10.3-py3-none-any.whl.metadata (172 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\sai rajagopal\\appdata\\roaming\\python\\python39\\site-packages (from langchain) (2.31.0)\n",
      "Collecting tenacity!=8.4.0,<10,>=8.1.0 (from langchain)\n",
      "  Using cached tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain_community)\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
      "  Downloading pydantic_settings-2.7.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting httpx<0.28.0,>=0.27.0 (from ollama)\n",
      "  Using cached httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting numpy<2,>=1.22.4 (from langchain)\n",
      "  Downloading numpy-1.26.4-cp39-cp39-win_amd64.whl.metadata (61 kB)\n",
      "     ---------------------------------------- 61.0/61.0 kB 3.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging in c:\\users\\sai rajagopal\\anaconda3\\lib\\site-packages (from faiss-cpu) (21.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\sai rajagopal\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (21.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\sai rajagopal\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\sai rajagopal\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\sai rajagopal\\anaconda3\\lib\\site-packages)\n",
      "DEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Sai Rajagopal\\anaconda3\\Lib\\site-packages\\~-mpy'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "daal4py 2021.3.0 requires daal==2021.2.3, which is not installed.\n",
      "spyder 5.1.5 requires pyqt5<5.13, which is not installed.\n",
      "spyder 5.1.5 requires pyqtwebengine<5.13, which is not installed.\n",
      "numba 0.54.1 requires numpy<1.21,>=1.17, but you have numpy 1.26.4 which is incompatible.\n",
      "scipy 1.7.1 requires numpy<1.23.0,>=1.16.5, but you have numpy 1.26.4 which is incompatible.\n",
      "tensorflow-intel 2.13.0 requires keras<2.14,>=2.13.1, but you have keras 2.10.0 which is incompatible.\n",
      "tensorflow-intel 2.13.0 requires numpy<=1.24.3,>=1.22, but you have numpy 1.26.4 which is incompatible.\n",
      "tensorflow-intel 2.13.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\n",
      "tensorflow-intel 2.13.0 requires tensorboard<2.14,>=2.13, but you have tensorboard 2.10.1 which is incompatible.\n",
      "tensorflow-intel 2.13.0 requires tensorflow-estimator<2.14,>=2.13.0, but you have tensorflow-estimator 2.10.0 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\sai rajagopal\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\sai rajagopal\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\sai rajagopal\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\sai rajagopal\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading marshmallow-3.23.1-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: anyio in c:\\users\\sai rajagopal\\anaconda3\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama) (2.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\sai rajagopal\\anaconda3\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama) (2021.10.8)\n",
      "Collecting httpcore==1.* (from httpx<0.28.0,>=0.27.0->ollama)\n",
      "  Using cached httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: idna in c:\\users\\sai rajagopal\\anaconda3\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama) (3.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\sai rajagopal\\anaconda3\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.2.0)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ollama)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.25->langchain)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting packaging (from faiss-cpu)\n",
      "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\sai rajagopal\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.25->langchain) (4.7.1)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.3,>=0.1.17->langchain)\n",
      "  Downloading orjson-3.10.12-cp39-none-win_amd64.whl.metadata (42 kB)\n",
      "     ---------------------------------------- 42.9/42.9 kB 2.2 MB/s eta 0:00:00\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.3,>=0.1.17->langchain)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.1 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading pydantic_core-2.27.1-cp39-none-win_amd64.whl.metadata (6.7 kB)\n",
      "Collecting typing-extensions>=4.7 (from langchain-core<0.4.0,>=0.3.25->langchain)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sai rajagopal\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (1.26.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\sai rajagopal\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (1.1.1)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.25->langchain)\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\sai rajagopal\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (0.4.3)\n",
      "Downloading langchain-0.3.12-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 1.0/1.0 MB 4.0 MB/s eta 0:00:00\n",
      "Downloading langchain_community-0.3.12-py3-none-any.whl (2.5 MB)\n",
      "   ---------------------------------------- 2.5/2.5 MB 4.3 MB/s eta 0:00:00\n",
      "Using cached ollama-0.4.4-py3-none-any.whl (13 kB)\n",
      "Downloading faiss_cpu-1.9.0.post1-cp39-cp39-win_amd64.whl (13.8 MB)\n",
      "   ---------------------------------------- 13.8/13.8 MB 5.4 MB/s eta 0:00:00\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "Using cached httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Using cached langchain_core-0.3.25-py3-none-any.whl (411 kB)\n",
      "Downloading langchain_text_splitters-0.3.3-py3-none-any.whl (27 kB)\n",
      "Using cached langsmith-0.2.3-py3-none-any.whl (320 kB)\n",
      "Downloading numpy-1.26.4-cp39-cp39-win_amd64.whl (15.8 MB)\n",
      "   ---------------------------------------- 15.8/15.8 MB 4.8 MB/s eta 0:00:00\n",
      "Downloading packaging-24.2-py3-none-any.whl (65 kB)\n",
      "   ---------------------------------------- 65.5/65.5 kB 3.5 MB/s eta 0:00:00\n",
      "Using cached pydantic-2.10.3-py3-none-any.whl (456 kB)\n",
      "Downloading pydantic_core-2.27.1-cp39-none-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 2.0/2.0 MB 4.9 MB/s eta 0:00:00\n",
      "Downloading pydantic_settings-2.7.0-py3-none-any.whl (29 kB)\n",
      "Using cached tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading marshmallow-3.23.1-py3-none-any.whl (49 kB)\n",
      "   ---------------------------------------- 49.5/49.5 kB ? eta 0:00:00\n",
      "Downloading orjson-3.10.12-cp39-none-win_amd64.whl (134 kB)\n",
      "   ---------------------------------------- 134.9/134.9 kB 4.0 MB/s eta 0:00:00\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Installing collected packages: typing-extensions, tenacity, python-dotenv, packaging, orjson, numpy, jsonpointer, httpx-sse, h11, annotated-types, typing-inspect, requests-toolbelt, pydantic-core, marshmallow, jsonpatch, httpcore, faiss-cpu, pydantic, httpx, dataclasses-json, pydantic-settings, ollama, langsmith, langchain-core, langchain-text-splitters, langchain, langchain_community\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.7.1\n",
      "    Uninstalling typing_extensions-4.7.1:\n",
      "      Successfully uninstalled typing_extensions-4.7.1\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 21.0\n",
      "    Uninstalling packaging-21.0:\n",
      "      Successfully uninstalled packaging-21.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.22.4\n",
      "    Uninstalling numpy-1.22.4:\n",
      "      Successfully uninstalled numpy-1.22.4\n",
      "  Attempting uninstall: annotated-types\n",
      "    Found existing installation: annotated-types 0.5.0\n",
      "    Uninstalling annotated-types-0.5.0:\n",
      "      Successfully uninstalled annotated-types-0.5.0\n",
      "  Attempting uninstall: pydantic-core\n",
      "    Found existing installation: pydantic_core 2.6.3\n",
      "    Uninstalling pydantic_core-2.6.3:\n",
      "      Successfully uninstalled pydantic_core-2.6.3\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.3.0\n",
      "    Uninstalling pydantic-2.3.0:\n",
      "      Successfully uninstalled pydantic-2.3.0\n",
      "Successfully installed annotated-types-0.7.0 dataclasses-json-0.6.7 faiss-cpu-1.9.0.post1 h11-0.14.0 httpcore-1.0.7 httpx-0.27.2 httpx-sse-0.4.0 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.12 langchain-core-0.3.25 langchain-text-splitters-0.3.3 langchain_community-0.3.12 langsmith-0.2.3 marshmallow-3.23.1 numpy-1.26.4 ollama-0.4.4 orjson-3.10.12 packaging-24.2 pydantic-2.10.3 pydantic-core-2.27.1 pydantic-settings-2.7.0 python-dotenv-1.0.1 requests-toolbelt-1.0.0 tenacity-9.0.0 typing-extensions-4.12.2 typing-inspect-0.9.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tensorflow-intel 2.13.0 requires typing-extensions<4.6.0,>=3.6.6, but you have typing-extensions 4.12.2 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install langchain langchain_community ollama faiss-cpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f612561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: typing-extensions in c:\\users\\sai rajagopal\\anaconda3\\lib\\site-packages (4.12.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\sai rajagopal\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\sai rajagopal\\anaconda3\\lib\\site-packages)\n",
      "DEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\sai rajagopal\\anaconda3\\lib\\site-packages (0.3.12)\n",
      "Requirement already satisfied: pydantic in c:\\users\\sai rajagopal\\anaconda3\\lib\\site-packages (2.10.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\sai rajagopal\\anaconda3\\lib\\site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\sai rajagopal\\anaconda3\\lib\\site-packages (from langchain) (1.4.22)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\sai rajagopal\\anaconda3\\lib\\site-packages (from langchain) (3.8.5)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\users\\sai rajagopal\\anaconda3\\lib\\site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.25 in c:\\users\\sai rajagopal\\anaconda3\\lib\\site-packages (from langchain) (0.3.25)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in c:\\users\\sai rajagopal\\anaconda3\\lib\\site-packages (from langchain) (0.3.3)\n",
      "Requirement already satisfied: langsmith<0.3,>=0.1.17 in c:\\users\\sai rajagopal\\anaconda3\\lib\\site-packages (from langchain) (0.2.3)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in c:\\users\\sai rajagopal\\anaconda3\\lib\\site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\sai rajagopal\\appdata\\roaming\\python\\python39\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\sai rajagopal\\anaconda3\\lib\\site-packages (from langchain) (9.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\sai rajagopal\\anaconda3\\lib\\site-packages (from pydantic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\sai rajagopal\\anaconda3\\lib\\site-packages (from pydantic) (2.27.1)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\sai rajagopal\\anaconda3\\lib\\site-packages (from pydantic) (4.12.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\sai rajagopal\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (21.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\sai rajagopal\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\sai rajagopal\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\sai rajagopal\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\sai rajagopal\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\sai rajagopal\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\sai rajagopal\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.25->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\sai rajagopal\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.25->langchain) (24.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\sai rajagopal\\anaconda3\\lib\\site-packages (from langsmith<0.3,>=0.1.17->langchain) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\sai rajagopal\\anaconda3\\lib\\site-packages (from langsmith<0.3,>=0.1.17->langchain) (3.10.12)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\sai rajagopal\\anaconda3\\lib\\site-packages (from langsmith<0.3,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sai rajagopal\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sai rajagopal\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sai rajagopal\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2021.10.8)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\sai rajagopal\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (1.1.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\sai rajagopal\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (2.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\sai rajagopal\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\sai rajagopal\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.2.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\sai rajagopal\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\sai rajagopal\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.25->langchain) (3.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\sai rajagopal\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\sai rajagopal\\anaconda3\\lib\\site-packages)\n",
      "DEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade typing-extensions\n",
    "!pip install --upgrade langchain pydantic\n",
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41657882",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.llms import Ollama\n",
    "\n",
    "# Load preprocessed content\n",
    "with open(\"processed_books_content.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    books_content = json.load(file)\n",
    "\n",
    "# Combine all book content into one string\n",
    "all_text = [\" \".join(books_content[book]) for book in books_content]\n",
    "combined_text = \"\\n\".join(all_text)\n",
    "\n",
    "# Split text into chunks for retrieval\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "documents = text_splitter.create_documents([combined_text])\n",
    "\n",
    "# Generate embeddings for the text\n",
    "embeddings = HuggingFaceEmbeddings()\n",
    "vectorstore = FAISS.from_documents(documents, embeddings)\n",
    "\n",
    "# Save the FAISS index for later use\n",
    "vectorstore.save_local(\"faiss_index\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e5dcb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0077de99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4c9357",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dceb013f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02bb43e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
